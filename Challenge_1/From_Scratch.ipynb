{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd89dc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2609 images belonging to 8 classes.\n",
      "Found 560 images belonging to 8 classes.\n",
      "Found 560 images belonging to 8 classes.\n",
      "Metal device set to: Apple M1 Pro\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 10s 54ms/step - loss: 2.1690 - accuracy: 0.2944 - val_loss: 6.2955 - val_accuracy: 0.1446\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 5s 30ms/step - loss: 1.8356 - accuracy: 0.3377 - val_loss: 6.0135 - val_accuracy: 0.1732\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.6911 - accuracy: 0.3706 - val_loss: 3.3697 - val_accuracy: 0.2000\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.5711 - accuracy: 0.4017 - val_loss: 1.4200 - val_accuracy: 0.4839\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.4657 - accuracy: 0.4603 - val_loss: 3.0781 - val_accuracy: 0.2589\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.4161 - accuracy: 0.4753 - val_loss: 1.8491 - val_accuracy: 0.3161\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.3908 - accuracy: 0.4849 - val_loss: 1.5147 - val_accuracy: 0.4464\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.3384 - accuracy: 0.5052 - val_loss: 2.3964 - val_accuracy: 0.2643\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.2776 - accuracy: 0.5259 - val_loss: 1.3789 - val_accuracy: 0.4625\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.2686 - accuracy: 0.5454 - val_loss: 2.3699 - val_accuracy: 0.2518\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 1.2095 - accuracy: 0.5512 - val_loss: 1.4112 - val_accuracy: 0.5018\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.1859 - accuracy: 0.5516 - val_loss: 1.3974 - val_accuracy: 0.5125\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.1809 - accuracy: 0.5707 - val_loss: 1.4048 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.1653 - accuracy: 0.5677 - val_loss: 1.5399 - val_accuracy: 0.4500\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.1449 - accuracy: 0.5745 - val_loss: 1.3295 - val_accuracy: 0.5196\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.0996 - accuracy: 0.5864 - val_loss: 1.0672 - val_accuracy: 0.6125\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 1.0735 - accuracy: 0.6044 - val_loss: 2.2469 - val_accuracy: 0.3857\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.0710 - accuracy: 0.5979 - val_loss: 1.2649 - val_accuracy: 0.5554\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.0309 - accuracy: 0.6175 - val_loss: 1.2778 - val_accuracy: 0.5607\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.0442 - accuracy: 0.6167 - val_loss: 2.0612 - val_accuracy: 0.3786\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 1.0515 - accuracy: 0.6194 - val_loss: 1.0939 - val_accuracy: 0.6161\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.9904 - accuracy: 0.6320 - val_loss: 1.5552 - val_accuracy: 0.4946\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.9916 - accuracy: 0.6332 - val_loss: 2.5930 - val_accuracy: 0.3071\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.9568 - accuracy: 0.6612 - val_loss: 1.1642 - val_accuracy: 0.5857\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.9721 - accuracy: 0.6351 - val_loss: 1.3009 - val_accuracy: 0.5286\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.9161 - accuracy: 0.6662 - val_loss: 1.3576 - val_accuracy: 0.5554\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.9377 - accuracy: 0.6501 - val_loss: 1.5847 - val_accuracy: 0.4696\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.9350 - accuracy: 0.6608 - val_loss: 0.8877 - val_accuracy: 0.6482\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 5s 27ms/step - loss: 0.8795 - accuracy: 0.6711 - val_loss: 1.0007 - val_accuracy: 0.6375\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.8576 - accuracy: 0.6780 - val_loss: 1.4407 - val_accuracy: 0.5286\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 5s 27ms/step - loss: 0.8963 - accuracy: 0.6700 - val_loss: 1.1763 - val_accuracy: 0.5482\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 5s 27ms/step - loss: 0.8254 - accuracy: 0.7030 - val_loss: 1.0003 - val_accuracy: 0.6339\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.8002 - accuracy: 0.7060 - val_loss: 0.7295 - val_accuracy: 0.7304\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.8217 - accuracy: 0.6976 - val_loss: 1.0191 - val_accuracy: 0.6250\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.7746 - accuracy: 0.7252 - val_loss: 2.2725 - val_accuracy: 0.4125\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.7822 - accuracy: 0.7210 - val_loss: 0.7784 - val_accuracy: 0.7339\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.7550 - accuracy: 0.7298 - val_loss: 1.2232 - val_accuracy: 0.5786\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.7595 - accuracy: 0.7328 - val_loss: 1.3838 - val_accuracy: 0.5196\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.7341 - accuracy: 0.7286 - val_loss: 0.8982 - val_accuracy: 0.6821\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.7163 - accuracy: 0.7348 - val_loss: 1.0480 - val_accuracy: 0.6179\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.7268 - accuracy: 0.7351 - val_loss: 1.0360 - val_accuracy: 0.6607\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.6855 - accuracy: 0.7528 - val_loss: 1.1646 - val_accuracy: 0.6536\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.6921 - accuracy: 0.7493 - val_loss: 0.8712 - val_accuracy: 0.6643\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.6729 - accuracy: 0.7620 - val_loss: 0.7527 - val_accuracy: 0.7375\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.6683 - accuracy: 0.7608 - val_loss: 0.8536 - val_accuracy: 0.6911\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.6748 - accuracy: 0.7555 - val_loss: 0.8234 - val_accuracy: 0.7357\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.6527 - accuracy: 0.7551 - val_loss: 0.6156 - val_accuracy: 0.7768\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.6289 - accuracy: 0.7704 - val_loss: 0.7601 - val_accuracy: 0.7393\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.6096 - accuracy: 0.7762 - val_loss: 1.0384 - val_accuracy: 0.6250\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.5999 - accuracy: 0.7781 - val_loss: 0.9826 - val_accuracy: 0.6357\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 5s 30ms/step - loss: 0.6067 - accuracy: 0.7723 - val_loss: 1.2298 - val_accuracy: 0.5875\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 5s 29ms/step - loss: 0.6241 - accuracy: 0.7693 - val_loss: 1.0075 - val_accuracy: 0.6482\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.5702 - accuracy: 0.7915 - val_loss: 1.0916 - val_accuracy: 0.6321\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 5s 28ms/step - loss: 0.6039 - accuracy: 0.7819 - val_loss: 0.7530 - val_accuracy: 0.7304\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 5s 30ms/step - loss: 0.5835 - accuracy: 0.7900 - val_loss: 0.7810 - val_accuracy: 0.7286\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 5s 28ms/step - loss: 0.5558 - accuracy: 0.7957 - val_loss: 0.6177 - val_accuracy: 0.7750\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 4s 27ms/step - loss: 0.5334 - accuracy: 0.8038 - val_loss: 1.0230 - val_accuracy: 0.6571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 11ms/step - loss: 0.5592 - accuracy: 0.8143\n",
      "\n",
      "Test metrics with data augmentation\n",
      "{'loss': 0.5591956377029419, 'accuracy': 0.8142856955528259}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 6\n",
    "\n",
    "\n",
    "classes = 8\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "dataset_dir = 'data1'\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "validation_dir = os.path.join(dataset_dir, 'validation')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Images are divided into folders, one for each class.\n",
    "# If the images are organized in such a way, we can exploit the\n",
    "# ImageDataGenerator to read them from disk.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of ImageDataGenerator for training and validation sets\n",
    "valid_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "test_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "# Create an instance of ImageDataGenerator with Data Augmentation\n",
    "aug_train_data_gen = ImageDataGenerator(rotation_range=40,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        fill_mode='reflect',\n",
    "                                        brightness_range=[0.5,1.5],\n",
    "                                        rescale=1/255.) # rescale value is multiplied to the image\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "aug_train_gen = aug_train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                                       target_size=(96,96),\n",
    "                                                       color_mode='rgb',\n",
    "                                                       classes=None, # can be set to labels\n",
    "                                                       class_mode='categorical',\n",
    "                                                       batch_size=16,\n",
    "                                                       shuffle=True,\n",
    "                                                       seed=seed)\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=16,\n",
    "                                               shuffle=False,\n",
    "                                               seed=seed)\n",
    "test_gen = test_data_gen.flow_from_directory(directory=test_dir,\n",
    "                                             target_size=(96, 96),\n",
    "                                             color_mode='rgb',\n",
    "                                             classes=None, # can be set to labels\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=16,\n",
    "                                             shuffle=False,\n",
    "                                             seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (96, 96, 3)\n",
    "epochs = 200\n",
    "\n",
    "def build_model(input_shape):\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    filters = [32, 64, 128, 256, 512]\n",
    "    kernel_size = [3, 3, 3, 3, 3]\n",
    "    nof_convolutional_layers = 5\n",
    "\n",
    "    lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.01)\n",
    "\n",
    "    #x = tfkl.UpSampling2D((2, 2))(input_layer)\n",
    "    x = tfkl.Conv2D(128, 3, strides=2, padding=\"same\")(input_layer)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Activation('relu')(x)\n",
    "\n",
    "    for i in range(nof_convolutional_layers):\n",
    "        x = tfkl.Conv2D( #no more separable\n",
    "            filters=filters[i],\n",
    "            kernel_size=kernel_size[i],\n",
    "            padding = 'same',\n",
    "            activation = 'relu',\n",
    "            kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "        )(x)\n",
    "        x = tfkl.BatchNormalization()(x)\n",
    "        if i != nof_convolutional_layers - 1:\n",
    "            x = tfkl.MaxPooling2D()(x)\n",
    "        else:\n",
    "            x = tfkl.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = tfkl.Flatten(name='Flatten')(x)\n",
    "    x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "    x = tfkl.Dense(units=512, name='Classifier', kernel_initializer=tfk.initializers.HeUniform(seed), activation='relu')(x)\n",
    "    x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "# Utility function to create folders and callbacks for training\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "    exps_dir = os.path.join('data_augmentation_experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "\n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Model checkpoint\n",
    "    # ----------------\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
    "                                                       save_weights_only=True,  # True to save only weights\n",
    "                                                       save_best_only=False)  # True to save only the best epoch\n",
    "    callbacks.append(ckpt_callback)\n",
    "\n",
    "    # Visualize Learning on Tensorboard\n",
    "    # ---------------------------------\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "\n",
    "    # By default shows losses and metrics for both training and validation\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "    callbacks.append(tb_callback)\n",
    "\n",
    "    # Early Stopping\n",
    "    # --------------\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "# Build model (for data augmentation training)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "#Training\n",
    "# Create folders and callbacks and fit\n",
    "aug_callbacks = create_folders_and_callbacks(model_name='CNN_Aug')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = aug_train_gen,\n",
    "    epochs = epochs,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = aug_callbacks,\n",
    ").history\n",
    "\n",
    "# Save best epoch model\n",
    "model.save(\"data_augmentation_experiments/TodaysBestSkip\")\n",
    "\n",
    "# Evaluate on test\n",
    "# Trained with data augmentation\n",
    "model_aug = tfk.models.load_model(\"data_augmentation_experiments/TodaysBestSkip\")\n",
    "model_aug_test_metrics = model_aug.evaluate(test_gen, return_dict=True)\n",
    "\n",
    "print()\n",
    "print(\"Test metrics with data augmentation\")\n",
    "print(model_aug_test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed29e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ca056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
